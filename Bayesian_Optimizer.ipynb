{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9ec92b",
   "metadata": {},
   "source": [
    "# Bayesian Optimizer using Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006156c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105343e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "from tensorflow.keras.layers import Reshape, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0942fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python package scikit-optimize (or skopt) for finding the best choices of these hyper-parameters.\n",
    "import skopt\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f45b7",
   "metadata": {},
   "source": [
    "## Hyper-Parameters\n",
    "1. The learning-rate\n",
    "\n",
    "2. The number of fully-connected / dense layers.\n",
    "\n",
    "3. The number of nodes for each of the dense layers.\n",
    "\n",
    "4. Activation function('sigmoid' or 'relu').\n",
    "\n",
    "5. Batch Size\n",
    "\n",
    "6. Optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adc78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search-ranges for hyper-parqameter\n",
    "batch_size = 128\n",
    "range_learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform', name='learning_rate')\n",
    "range_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "range_num_dense_nodes = Integer(low=5, high=512, name='num_dense_nodes')\n",
    "activation_function = Categorical(categories=['relu', 'sigmoid'], name='activation')\n",
    "\n",
    "dimensions = [range_learning_rate, range_num_dense_layers, range_num_dense_nodes, activation_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = [1e-5, 1, 16, 'relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the training-progress for all parameter-combinations\n",
    "def log_dir_name(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./logs/lr_{0:.0e}_layers_{1}_nodes_{2}_{3}/\"\n",
    "    \n",
    "    log_dir = s.format(learning_rate, num_dense_layers, \n",
    "                       num_dense_nodes, activation)\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5695028",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset\n",
    "\n",
    "70.000 images and class-numbers for the images.\n",
    "- Training-set:\t\t48999\n",
    "- Validation-set:\t14000\n",
    "- Test-set:\t\t7001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7109450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "DATASET_SIZE = 70000\n",
    "TRAIN_RATIO = 5/7\n",
    "VALIDATION_RATIO = (1-5/7)/4\n",
    "TEST_RATIO = ((1-5/7)/4)*3\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((60000,784)).astype('float32') / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "x_test = x_test.reshape((10000,784)).astype('float32') / 255.0\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "x = np.concatenate([x_train, x_test])\n",
    "y = np.concatenate([y_train, y_test])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=(1-TRAIN_RATIO))\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_val, y_val, test_size=((TEST_RATIO/(VALIDATION_RATIO+TEST_RATIO))))\n",
    "\n",
    "print('Training data: {}. {}'.format(x_train.shape, y_train.shape))\n",
    "print('Validation data: {}. {}'.format(x_val.shape, y_val.shape))\n",
    "print('Test data: {}. {}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b8ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "img_size_flat = 784\n",
    "img_shape = (28, 28)\n",
    "img_shape_full = (28, 28, 1)\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "validation_data = (x_val, y_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bac49d",
   "metadata": {},
   "source": [
    "## Helper-function for plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b10e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9db57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_cls = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "images = x_test[0:9]\n",
    "cls_true = y_test_cls[0:9]\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred):\n",
    "    # Boolean array whether the predicted class is incorrect.\n",
    "    incorrect = (cls_pred != y_test_cls)\n",
    "\n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = x_test[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = y_test_cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25427e",
   "metadata": {},
   "source": [
    "## Hyper-Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d057d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
    "    \n",
    "    model = Sequential()\n",
    "    # Add fully-connected / dense layers.\n",
    "    for i in range(num_dense_layers):\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "        model.add(Dense(num_dense_nodes, activation=activation, name=name))\n",
    "    # Last fully-connected / dense layer with softmax-activation\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Use the Adam method for training the network.\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    #optimizer = sel_optimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    # In Keras we need to compile the model so it can be trained.\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "path_best_model = 'best_trained_model.h5'\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
    "    # Print the hyper-parameters.\n",
    "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print('num_dense_nodes:', num_dense_nodes)\n",
    "    print('activation:', activation)\n",
    "    print()\n",
    "    \n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(learning_rate=learning_rate, num_dense_layers=num_dense_layers,\n",
    "                         num_dense_nodes=num_dense_nodes, activation=activation)\n",
    "\n",
    "\n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(learning_rate, num_dense_layers, \n",
    "                           num_dense_nodes, activation)\n",
    "\n",
    "    # saves the log-files for TensorBoard.\n",
    "    callback_log = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True,\n",
    "                               write_grads=False, write_images=False)\n",
    "   \n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x=x_train, y=y_train, \n",
    "                        epochs=3, batch_size=batch_size, \n",
    "                        validation_data=validation_data, \n",
    "                        callbacks=[callback_log])\n",
    "\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    accuracy = history.history['val_accuracy'][-1]\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "    # Save the new model\n",
    "    global best_accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        model.save(path_best_model)\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92926fd0",
   "metadata": {},
   "source": [
    "## Run Test for default hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3385c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitness(x=default_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488651e",
   "metadata": {},
   "source": [
    "## Run the Hyper-Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a0143",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "search_result = gp_minimize(func=fitness, dimensions=dimensions, \n",
    "                            acq_func='EI', # Expected Improvement.\n",
    "                            n_calls=15, x0=default_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5ef7b",
   "metadata": {},
   "source": [
    "## Optimization Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best Hyper-Parameters\n",
    "search_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942dff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_dict(point):\n",
    "    return {\"lat\": point.y, \"lng\": point.x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = search_result.space\n",
    "#space.point_to_dict(search_result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e87544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a negative number because the Bayesian optimizer performs minimization\n",
    "search_result.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cb573",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(search_result.func_vals, search_result.x_iters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f4afb",
   "metadata": {},
   "source": [
    "## Visualization of Hyper-parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce7102",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# activation parameter, which shows the distribution of samples during the hyper-parameter optimization.\n",
    "fig = plot_histogram(result=search_result, dimension_identifier='activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate and num_dense_layers\n",
    "fig = plot_objective_2D(result=search_result, \n",
    "                        dimension_identifier1='learning_rate', \n",
    "                        dimension_identifier2='num_dense_layers', \n",
    "                        levels=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_names = ['learning_rate', 'num_dense_nodes', 'num_dense_layers']\n",
    "\n",
    "fig = plot_objective(result=search_result, plot_dims =dim_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d668fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_evaluations(result=search_result, plot_dims=dim_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873c285",
   "metadata": {},
   "source": [
    "## Evaluate Best Model on TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cdebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(path_best_model)\n",
    "result = model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b226fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Test results\n",
    "images = x_test[0:9]\n",
    "cls_true = y_test_cls[0:9]\n",
    "y_pred = model.predict(x=images)\n",
    "cls_pred = np.argmax(y_pred,axis=1)\n",
    "\n",
    "plot_images(images=images, cls_true=cls_true, cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12952c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime(\"%H:%M:%S\",time.gmtime(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2374a2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
