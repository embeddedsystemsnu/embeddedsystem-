{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Silence TensorFlow messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras import regularizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "MODEL_DIR = './models'\n",
    "FLOAT_MODEL = 'float_model.h5'\n",
    "QAUNT_MODEL = 'quantized_model.h5'\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print('Training data: {}. {}'.format(x_train.shape, y_train.shape))\n",
    "print('Test data: {}. {}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449df2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(10,10))\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(5):\n",
    "    axs[i].imshow(x_train[i], 'gray')\n",
    "    axs[i].set_title('Label: {}'.format(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea51553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "# 라벨 값을 one-hot-encoding으로 바꿈\n",
    "\n",
    "x_train = x_train.reshape((60000,28,28,1)).astype('float32') / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "x_test = x_test.reshape((10000,28,28,1)).astype('float32') / 255.0\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "x_train_flat = x_train.reshape((-1, 784))\n",
    "x_test_flat = x_test.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create saparated datasets for train,validate,test\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train[:50000], y_train[:50000])).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train[5000:], y_train[5000:])).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "train_dataset_flat = tf.data.Dataset.from_tensor_slices((x_train_flat[:50000], y_train[:50000])).batch(batch_size)\n",
    "val_dataset_flat = tf.data.Dataset.from_tensor_slices((x_train_flat[5000:], y_train[5000:])).batch(batch_size)\n",
    "test_dataset_flat = tf.data.Dataset.from_tensor_slices((x_test_flat, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349df6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customcnn():\n",
    "    # create a cnn model\n",
    "    inputs = keras.Input(shape=(28,28,1))\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1))(inputs)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_customcnn_model')\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\"\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, \n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def customFC():\n",
    "    # create a Fully Connected model\n",
    "    inputs = keras.Input(shape=(28,28))\n",
    "    inputs = keras.Input(name='input', shape=(784,))\n",
    "\n",
    "    x = layers.Dense(300, name='hidden_1', activation='relu')(inputs)\n",
    "    x = layers.Dense(100, name='hidden_2', activation='relu')(x)\n",
    "    \n",
    "\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_customcnn_model')\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, \n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6381385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build cnn model\n",
    "print(\"\\nCreate custom cnn..\")\n",
    "model = customcnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 10 epochs using a dataset\n",
    "print(\"\\nFit on dataset..\")\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ff159",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].plot(history.history['loss'], 'b')\n",
    "axs[0].plot(history.history['val_loss'], 'r')\n",
    "axs[0].set_title('Training Loss / Validation Loss')\n",
    "axs[0].set(xlabel='Epochs', ylabel='loss')\n",
    "\n",
    "axs[1].plot(history.history['accuracy'], 'b')\n",
    "axs[1].plot(history.history['val_accuracy'], 'r')\n",
    "axs[1].set_title('Training Accuracy / Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with test data\n",
    "print(\"\\nEvaluate model on test dataset..\")\n",
    "import time\n",
    "\n",
    "loss, acc = model.evaluate(test_dataset)  # returns loss and metrics\n",
    "print(\"Test Loss: %.3f\" % loss)\n",
    "print(\"Test Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e650a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build cnn model\n",
    "print(\"\\nCreate custom FC..\")\n",
    "model_FC = customFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03810e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model for 10 epochs using a dataset\n",
    "print(\"\\nFit on dataset..\")\n",
    "history_FC = model_FC.fit(train_dataset_flat, epochs=10, validation_data=val_dataset_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5df010",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axs[0].plot(history_FC.history['loss'], 'b')\n",
    "axs[0].plot(history_FC.history['val_loss'], 'r')\n",
    "axs[0].set_title('Training Loss / Validation Loss')\n",
    "axs[0].set(xlabel='Epochs', ylabel='loss')\n",
    "\n",
    "axs[1].plot(history_FC.history['accuracy'], 'b')\n",
    "axs[1].plot(history_FC.history['val_accuracy'], 'r')\n",
    "axs[1].set_title('Training Accuracy / Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bc3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with test data\n",
    "print(\"\\nEvaluate model on test dataset..\")\n",
    "import time\n",
    "\n",
    "loss, acc = model_FC.evaluate(test_dataset_flat)  # returns loss and metrics\n",
    "print(\"Test Loss: %.3f\" % loss)\n",
    "print(\"Test Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CNN model\n",
    "path = os.path.join(MODEL_DIR, FLOAT_MODEL)\n",
    "print(\"\\nSave trained model to{}.\".format(path))\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ec6c6",
   "metadata": {},
   "source": [
    "## MNIST model quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9546b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 32-bit float model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/float_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "#saving converted model in \"converted_model.tflite\" file\n",
    "open(\"./models/converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98512b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_test).batch(1).take(100):\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8-bit integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6843f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "#converter.inference_input_type = tf.uint8\n",
    "#converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_int8 = converter.convert()\n",
    "#saving converted model in \"converted_model.tflite\" file\n",
    "open(\"./models/converted_quant_model_int8.tflite\", \"wb\").write(tflite_model_quant_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 16-bit float quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model_float16 = converter.convert()\n",
    "#saving converted model in \"converted_model.tflite\" file\n",
    "open(\"./models/converted_quant_model_float16.tflite\", \"wb\").write(tflite_quant_model_float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer only: 16-bit activations with 8-bit weights (experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b055e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n",
    "tflite_quant_model_act16_wei_8 = converter.convert()\n",
    "#saving converted model in \"converted_model.tflite\" file\n",
    "open(\"./models/converted_quant_model_act16_wei_8.tflite\", \"wb\").write(tflite_quant_model_act16_wei_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f058931",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"32-bit Float model in Mb:\", \n",
    "      os.path.getsize('./models/converted_model.tflite') / float(2**20))\n",
    "print(\"16-bit Float Quantized model in Mb:\", \n",
    "      os.path.getsize('./models/converted_quant_model_float16.tflite') / float(2**20))\n",
    "print(\"Compression ratio:\", \n",
    "      os.path.getsize('./models/converted_model.tflite')/os.path.getsize('./models/converted_quant_model_float16.tflite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"32-bit Float model in Mb:\", \n",
    "      os.path.getsize('./models/converted_model.tflite') / float(2**20))\n",
    "print(\"16-bit(A) 8-bit(W) int Quantized model in Mb:\", \n",
    "      os.path.getsize('./models/converted_quant_model_act16_wei_8.tflite') / float(2**20))\n",
    "print(\"Compression ratio:\", \n",
    "      os.path.getsize('./models/converted_model.tflite')/os.path.getsize('./models/converted_quant_model_act16_wei_8.tflite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86f48f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the floating point trained model\n",
    "print('Load float model..')\n",
    "path = os.path.join(MODEL_DIR, FLOAT_MODEL)\n",
    "print(path)\n",
    "try:\n",
    "    float_model = models.load_model(path)\n",
    "except:\n",
    "    print('\\nError:load float model failed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input dimensions of the floating-point model\n",
    "height = float_model.input_shape[1]\n",
    "width = float_model.input_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476500b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run vitis-quantization\n",
    "print('\\nRun quantization..')\n",
    "quantizer = vitis_quantize.VitisQuantizer(float_model)\n",
    "quantized_model = quantizer.quantize_model(calib_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model\n",
    "path = os.path.join(MODEL_DIR, QAUNT_MODEL)\n",
    "quantized_model.save(path)\n",
    "print('\\nSaved quantized model as',path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(MODEL_DIR, QAUNT_MODEL)\n",
    "with vitis_quantize.quantize_scope():\n",
    "    quantized_model = models.load_model(path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2553e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "print('\\nCompile model..')\n",
    "quantized_model.compile(optimizer=\"rmsprop\", \n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4152761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model with test data\n",
    "print(\"\\nEvaluate model on test Dataset\")\n",
    "loss, acc = quantized_model.evaluate(test_dataset)  # returns loss and metrics\n",
    "print(\"Test Loss: %.3f\" % loss)\n",
    "print(\"Test Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc11cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"-----------------------------------------\"\n",
    "!echo \"COMPILING MODEL FOR ZCU104..\"\n",
    "!echo \"-----------------------------------------\"\n",
    "\n",
    "!vai_c_tensorflow2 \\\n",
    "            --model ./models/quantized_model.h5 \\\n",
    "            --arch /opt/vitis_ai/compiler/arch/DPUCZDX8G/ZCU104/arch.json \\\n",
    "            --output_dir ./compiled_model/zcu104 \\\n",
    "            --net_name customcnn\n",
    "\n",
    "!echo \"-----------------------------------------\"\n",
    "!echo \"MODEL COMPILED\"\n",
    "!echo \"-----------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbcf24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in quantized_model.non_trainable_weights:\n",
    "    print(w)\n",
    "\n",
    "\n",
    "quantized_model.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec912ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def TFLiteInference(model_path,x_test,y_test):\n",
    "\n",
    "    #Step 1. Load TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    print(tflite_interpreter.get_input_details())\n",
    "    # Get indexes of input and output layers\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    sum_correct=0.0\n",
    "    sum_time=0.0\n",
    "    for idx, data in enumerate(zip(x_test,y_test)):\n",
    "        image=data[0]\n",
    "        label=data[1]\n",
    "        image=tf.expand_dims(image, axis=0) #shape will be [1,32,32,3]\n",
    "        \n",
    "        s_time=time.time()\n",
    "        #Step 2. Transform input data\n",
    "        interpreter.set_tensor(input_index,image)\n",
    "        #Step 3. Run inference\n",
    "        interpreter.invoke()\n",
    "        #Step 4. Interpret output\n",
    "        pred=interpreter.get_tensor(output_index)\n",
    "        \n",
    "        sum_time+=time.time()-s_time\n",
    "        if np.argmax(pred)== np.argmax(label):\n",
    "            sum_correct+=1.0\n",
    "    \n",
    "    mean_acc=sum_correct / float(idx+1)\n",
    "    mean_time=sum_time / float(idx+1)\n",
    "\n",
    "    print(f'Accuracy of TFLite model: {mean_acc}')\n",
    "    print(f'Inference time of TFLite model: {mean_time}')\n",
    "    \n",
    "TFLiteInference(model_path='./models/converted_model.tflite',x_test=x_test,y_test=y_test)\n",
    "TFLiteInference(model_path='./models/converted_quant_model_float16.tflite',x_test=x_test,y_test=y_test)\n",
    "TFLiteInference(model_path='./models/converted_quant_model_act16_wei_8.tflite',x_test=x_test,y_test=y_test)\n",
    "TFLiteInference(model_path='./models/converted_quant_model_int8.tflite',x_test=x_test,y_test=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb945f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cc204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
