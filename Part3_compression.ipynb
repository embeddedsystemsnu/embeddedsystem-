{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3018b71e",
   "metadata": {},
   "source": [
    "# Part 3: Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d607a01",
   "metadata": {},
   "source": [
    "## Load MNIST dataset from tf.keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52007018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27675d",
   "metadata": {},
   "source": [
    "### Let's print some information about the dataset\n",
    "Print the the dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa05c20d",
   "metadata": {},
   "source": [
    "## Now construct a model\n",
    "We'll use the same architecture as in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout,Flatten, Dense, Activation, BatchNormalization, Conv2D, MaxPooling2D,InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "input_shape=(28,28,1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd2a9d",
   "metadata": {},
   "source": [
    "## Train sparse\n",
    "This time we'll use the Tensorflow model optimization sparsity to train a sparse model (forcing many weights to '0'). In this instance, the target sparsity is 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be67b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.75, begin_step=0, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e580cb",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use the same settings as the model for part 1: Adam optimizer with categorical crossentropy loss.\n",
    "The callbacks will decay the learning rate and save the model into a directory 'model_mnist_cnn3'\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU.\n",
    "If you've restarted the notebook kernel after training once, set `train = False` to load the trained model rather than training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580dd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "train =False\n",
    "\n",
    "\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'model_mnist_cnn3')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(x_train, y_train, batch_size=128,\n",
    "              epochs=30, validation_split=0.2, shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "    model = strip_pruning(model)\n",
    "    model.save('model_mnist_cnn3/KERAS_check_best_model.h5')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    model = load_model('model_mnist_cnn3/KERAS_check_best_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b59353",
   "metadata": {},
   "source": [
    "## Check sparsity\n",
    "Make a quick check that the model was indeed trained sparse. We'll just make a histogram of the weights of the 1st layer, and hopefully observe a large peak in the bin containing '0'. Note logarithmic y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0364c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.summary()\n",
    "w = model.layers[0].weights[0].numpy()\n",
    "h, b = np.histogram(w, bins=100)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.bar(b[:-1], h, width=b[1]-b[0])\n",
    "plt.semilogy()\n",
    "print('% of zeros = {}'.format(np.sum(w==0)/np.size(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d9a98",
   "metadata": {},
   "source": [
    "## Check performance\n",
    "How does this 75% sparse model compare against the unpruned model? Let's report the accuracy and make a ROC curve. The pruned model is shown with solid lines, the unpruned model from part 1 is shown with dashed lines.\n",
    "**Make sure you've trained the model from part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729244d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "model_ref = load_model('model_mnist_cnn/KERAS_check_best_model.h5')\n",
    "\n",
    "y_ref = model_ref.predict(x_test)\n",
    "y_prune = model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy unpruned: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
    "print(\"Accuracy pruned:   {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_prune, axis=1))))\n",
    "\n",
    "mnist_classes=['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_ref, mnist_classes)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_prune, mnist_classes, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['unpruned', 'pruned'],\n",
    "            loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c57874",
   "metadata": {},
   "source": [
    "# Convert the model to FPGA firmware with hls4ml\n",
    "Let's use the default configuration: `ap_fixed<16,6>` precision everywhere and `ReuseFactor=1`, so we can compare with the part 1 model. We need to use `strip_pruning` to change the layer types back to their originals.\n",
    "\n",
    "**The synthesis will take a while**\n",
    "\n",
    "While the C-Synthesis is running, we can monitor the progress looking at the log file by opening a terminal from the notebook home, and executing:\n",
    "\n",
    "`tail -f mnist-hls-test3/vivado_hls.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39666a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import keras_to_hls\n",
    "import yaml\n",
    "\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['Backend']='VivadoAccelerator'\n",
    "config['OutputDir'] = 'mnist-hls-test3'\n",
    "config['ProjectName'] = 'myproject_mnist_cnn3'\n",
    "config['XilinxPart']= 'xczu7ev-ffvc1156-2-e'\n",
    "config['Board'] = 'zcu104'\n",
    "config['ClockPeriod'] = 5\n",
    "config['IOType'] = 'io_stream'\n",
    "config['HLSConfig']={}\n",
    "config['HLSConfig']['Model']={}\n",
    "config['HLSConfig']['Model']=config['Model']\n",
    "config['HLSConfig']['LayerName']=config['LayerName']\n",
    "del config['Model']\n",
    "del config['LayerName']\n",
    "config['AcceleratorConfig']={}\n",
    "config['AcceleratorConfig']['Interface'] = 'axi_stream'\n",
    "config['AcceleratorConfig']['Driver'] = 'python'\n",
    "config['AcceleratorConfig']['Precision']={}\n",
    "config['AcceleratorConfig']['Precision']['Input']= 'float'\n",
    "config['AcceleratorConfig']['Precision']['Output']= 'float'\n",
    "config['KerasModel'] = model\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = keras_to_hls(config)\n",
    "hls_model.compile()\n",
    "os.environ['PATH'] = '/workspace/home/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "hls_model.build(csim=False,synth=True,export=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b09f8",
   "metadata": {},
   "source": [
    "# And now print the report, compare this to the report from Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report(config['OutputDir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('mnist-hls-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e690bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
